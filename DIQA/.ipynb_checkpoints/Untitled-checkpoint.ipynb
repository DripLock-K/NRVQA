{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a517c9-3026-4ab4-9d3f-e15ba03dff3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aye\n",
      "Model: \"objective_error_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " original_image (InputLayer)  [(1, None, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (1, None, None, 48)       480       \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (1, None, None, 48)       20784     \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (1, None, None, 64)       27712     \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (1, None, None, 64)       36928     \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (1, None, None, 64)       36928     \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (1, None, None, 64)       36928     \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (1, None, None, 128)      73856     \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (1, None, None, 128)      147584    \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (1, None, None, 1)        129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 381,329\n",
      "Trainable params: 381,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0\n",
      "epoch:0 step:0 loss= 0.03805604\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import imquality\n",
    "# from imquality import datasets\n",
    "from utils import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "\n",
    "def image_preprocess(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image_low = gaussian_filter(image, 16, 7/6)\n",
    "    image_low = rescale(image_low, 1/4, method=tf.image.ResizeMethod.BICUBIC)\n",
    "    image_low = tf.image.resize(image_low, size=image_shape(\n",
    "        image), method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "    return image-tf.cast(image_low, image.dtype)\n",
    "\n",
    "\n",
    "def error_map(reference: tf.Tensor, distorted: tf.Tensor, p: float = 0.2):\n",
    "    return tf.pow(tf.abs(reference-distorted), p)\n",
    "\n",
    "\n",
    "def reliability_map(distorted: tf.Tensor, alpha: float) -> tf.Tensor:\n",
    "    return 2/(1+tf.exp(-alpha*tf.abs(distorted)))-1\n",
    "\n",
    "\n",
    "def average_reliability_map(distorted: tf.Tensor, alpha: float) -> tf.Tensor:\n",
    "    r = reliability_map(distorted, alpha)\n",
    "    return r/tf.reduce_mean(r)\n",
    "\n",
    "\n",
    "def loss(model, x, y_true, r):\n",
    "    y_pred = model(x)\n",
    "    return tf.reduce_mean(tf.square((y_true-y_pred)*r))\n",
    "\n",
    "\n",
    "def gradient(model, x, y_true, r):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, x, y_true, r)\n",
    "        return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.Nadam(learning_rate=10**-4)\n",
    "\n",
    "\n",
    "def calculate_error_map(features):\n",
    "    I_d = image_preprocess(features['dist_img'])\n",
    "    I_r = image_preprocess(features['ref_img'])\n",
    "    # I_d = image_preprocess(features[0])\n",
    "    # I_r = image_preprocess(features[1])\n",
    "    # I_d, I_r = features\n",
    "    r = rescale(average_reliability_map(I_d, 0.2), 1/4)\n",
    "    e_gt = rescale(error_map(I_r, I_d, 0.2), 1/4)\n",
    "\n",
    "    return (I_d, e_gt, r)\n",
    "# builder = datasets.LiveIQA(data_dir=\"./LIVE/\")\n",
    "# builder.download_and_prepare(download_dir=\"./LIVE/\")\n",
    "# builder = tfds.core.builder_from_directory()\n",
    "\n",
    "# ds = builder.as_dataset(shuffle_files=True)['train']\n",
    "# ds = ds.shuffle(1024).batch(1)\n",
    "data_dir = './imquality/datasets/kadid10k'\n",
    "df = pd.read_csv(f'{data_dir}/dmos.csv')\n",
    "df_dict = df.to_dict('records')\n",
    "# train = ds.map(calculate_error_map)\n",
    "data = []\n",
    "# print('heyyeyeyey')\n",
    "j = 0\n",
    "for i in df_dict:\n",
    "    frame = cv2.imread(f'{data_dir}/images/{i[\"dist_img\"]}')\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    im = tf.constant(frame)\n",
    "    # im = image_preprocess(im)\n",
    "    frame2 = cv2.imread(f'{data_dir}/images/{i[\"ref_img\"]}')\n",
    "    frame2 = np.expand_dims(frame2, axis=0)\n",
    "    im2 = tf.constant(frame2)\n",
    "    # im2 = image_preprocess(im2)\n",
    "    data.append({\n",
    "        'dist_img': im,\n",
    "        'ref_img': im2,\n",
    "        'dmos': i['dmos'],\n",
    "    })\n",
    "    j+=1\n",
    "    if j==5:\n",
    "        break\n",
    "    # print('ab')\n",
    "# print(data[:5])\n",
    "print('aye')\n",
    "train = map(calculate_error_map, data)\n",
    "input = tf.keras.Input(shape=(None, None, 1),\n",
    "                       batch_size=1, name='original_image')\n",
    "f = tf.keras.layers.Conv2D(48, (3, 3), name='Conv1',\n",
    "                           activation='relu', padding='same')(input)\n",
    "f = tf.keras.layers.Conv2D(48, (3, 3), name='Conv2',\n",
    "                           activation='relu', padding='same', strides=(2, 2))(f)\n",
    "f = tf.keras.layers.Conv2D(64, (3, 3), name='Conv3',\n",
    "                           activation='relu', padding='same')(f)\n",
    "f = tf.keras.layers.Conv2D(64, (3, 3), name='Conv4',\n",
    "                           activation='relu', padding='same', strides=(2, 2))(f)\n",
    "f = tf.keras.layers.Conv2D(64, (3, 3), name='Conv5',\n",
    "                           activation='relu', padding='same')(f)\n",
    "f = tf.keras.layers.Conv2D(64, (3, 3), name='Conv6',\n",
    "                           activation='relu', padding='same')(f)\n",
    "f = tf.keras.layers.Conv2D(128, (3, 3), name='Conv7',\n",
    "                           activation='relu', padding='same')(f)\n",
    "f = tf.keras.layers.Conv2D(128, (3, 3), name='Conv8',\n",
    "                           activation='relu', padding='same')(f)\n",
    "g = tf.keras.layers.Conv2D(1, (1, 1), name='Conv9',\n",
    "                           padding='same', activation='linear')(f)\n",
    "\n",
    "objective_error_model = tf.keras.Model(input, g, name='objective_error_model')\n",
    "objective_error_model.summary()\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(epoch)\n",
    "    epoch_accuracy = tf.keras.metrics.MeanSquaredError()\n",
    "    step = 0\n",
    "    for I_d, e_gt, r in train:\n",
    "        loss_value, gradients = gradient(objective_error_model, I_d, e_gt, r)\n",
    "        _ = optimizer.apply_gradients(\n",
    "            zip(gradients, objective_error_model.trainable_weights))\n",
    "        _ = epoch_accuracy(e_gt, objective_error_model(I_d))\n",
    "\n",
    "        if(step % 100 == 0):\n",
    "            print(\"epoch:%s step:%s loss= %s\" %\n",
    "                  (epoch, step, epoch_accuracy.result().numpy()))\n",
    "        step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ddc1781-4865-447e-b3b8-d9d2eb4093e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subjective_error_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " original_image (InputLayer)  [(1, None, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (1, None, None, 48)       480       \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (1, None, None, 48)       20784     \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (1, None, None, 64)       27712     \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (1, None, None, 64)       36928     \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (1, None, None, 64)       36928     \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (1, None, None, 64)       36928     \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (1, None, None, 128)      73856     \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (1, None, None, 128)      147584    \n",
      "                                                                 \n",
      " global_average_pooling2d_9   (1, 128)                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (1, 128)                  16512     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (1, 1)                    129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397,841\n",
      "Trainable params: 397,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "v = tf.keras.layers.GlobalAveragePooling2D(data_format='channels_last')(f)\n",
    "h = tf.keras.layers.Dense(128, activation='relu')(v)\n",
    "h = tf.keras.layers.Dense(1)(h)\n",
    "subjective_error_model = tf.keras.Model(\n",
    "    input, h, name='subjective_error_model')\n",
    "subjective_error_model.compile(optimizer=optimizer, loss=tf.losses.MeanSquaredError(\n",
    "), metrics=[tf.metrics.MeanSquaredError()])\n",
    "subjective_error_model.summary()\n",
    "\n",
    "\n",
    "def calculate_subjective_score(features):\n",
    "    # I_d = image_preprocess(features['dist_img'])\n",
    "    mos = features['dmos']\n",
    "    return mos # (I_d, mos)\n",
    "train2X = list(map(lambda _: [image_preprocess(_['dist_img'])], data))\n",
    "train2Y = np.array(list(map(calculate_subjective_score, data)))\n",
    "train2Y = train2Y.reshape((1, train2Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6a76dbe-2a98-486b-bbb1-8015c6e570ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 384, 512, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a960c6d-41de-4587-9094-7a302742ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"subjective_error_model\" expects 1 input(s), but it received 5 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None, 384, 512, 1) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KRISHN~1\\AppData\\Local\\Temp/ipykernel_71044/1960450604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print(list(train2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubjective_error_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain2Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubjective_error_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubjective_error_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models2/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Krishna Baghel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"subjective_error_model\" expects 1 input(s), but it received 5 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 384, 512, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None, 384, 512, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# print(list(train2))\n",
    "history = subjective_error_model.fit(train2X, train2Y, epochs=100)\n",
    "subjective_error_model.save_weights(\"models/\")\n",
    "tf.saved_model.save(subjective_error_model, \"models2/\")\n",
    "\n",
    "# sample = next(iter(ds))\n",
    "sample = data[0]\n",
    "I_d = image_preprocess(sample['dist_img'])\n",
    "target = sample['dmos'][0]\n",
    "prediction = subjective_error_model.predict(I_d)[0][0]\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03738bfa-5b23-4203-ba8f-ab93a277693b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KRISHN~1\\AppData\\Local\\Temp/ipykernel_71044/1955631167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m                     \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{colname}.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mmat2csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./dmos.mat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\KRISHN~1\\AppData\\Local\\Temp/ipykernel_71044/1955631167.py\u001b[0m in \u001b[0;36mmat2csv\u001b[1;34m(file_mat, index)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfieldname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# ignore struct fields different from \"data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def mat2csv(file_mat, index=False):\n",
    "    mat = loadmat(file_mat, squeeze_me=True)\n",
    "    print(mat)\n",
    "    for colname in mat.keys():\n",
    "        # ignore private column names\n",
    "        if colname.startswith(\"__\"):\n",
    "            continue\n",
    "        \n",
    "        for fieldname in mat[colname].dtype.names:\n",
    "\n",
    "            # ignore struct fields different from \"data\"\n",
    "            # rename or uncomment it to match your needs\n",
    "            if fieldname != \"data\":\n",
    "                continue\n",
    "\n",
    "            # get dataset values from \"data\" field for current column\n",
    "            element = mat[colname][fieldname].item()\n",
    "\n",
    "            # it could exist other instances (eg. str) and other dimensions (eg. 1D)\n",
    "            # update these lines if you need something different than this\n",
    "            if isinstance(element, np.ndarray):\n",
    "                if len(element.shape) == 2:\n",
    "                    _, cols = element.shape\n",
    "                    data = {f\"x{i}\" : element[:, i] for i in range(cols)}\n",
    "                    pd.DataFrame(data).to_csv(f\"{colname}.csv\", index=False)\n",
    "\n",
    "mat2csv(\"./dmos.mat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
